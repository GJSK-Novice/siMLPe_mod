{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Code to run in bash console\n",
    "# cd exps/baseline_h36m\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import os, sys\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from config import config\n",
    "\n",
    "import model as models\n",
    "from datasets.h36m import H36MDataset\n",
    "from utils.logger import get_logger, print_and_log_info\n",
    "from utils.pyt_utils import link_file, ensure_dir\n",
    "from datasets.h36m_eval import H36MEval\n",
    "\n",
    "from custom_test import test\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# cuda setting to make result deterministic\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--exp-name', type=str, default=None, help='=exp name')\n",
    "parser.add_argument('--seed', type=int, default=888, help='=seed')\n",
    "parser.add_argument('--temporal-only', action='store_true', help='=temporal only')\n",
    "parser.add_argument('--layer-norm-axis', type=str, default='spatial', help='=layernorm axis')\n",
    "# default is False for 'store_true'\n",
    "parser.add_argument('--with-normalization', action='store_true', help='=use layernorm')\n",
    "parser.add_argument('--spatial-fc', action='store_true', help='=use only spatial fc')\n",
    "parser.add_argument('--num', type=int, default=64, help='=num of blocks')\n",
    "parser.add_argument('--weight', type=float, default=1., help='=loss weight')\n",
    "\n",
    "# pass argument without command line\n",
    "import shlex\n",
    "argString = '--seed 888 --exp-name baseline.txt --layer-norm-axis spatial --with-normalization --num 48'\n",
    "args = parser.parse_args(shlex.split(argString))\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "acc_log = open(args.exp_name, 'a')\n",
    "torch.manual_seed(args.seed)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "config.motion_fc_in.temporal_fc = args.temporal_only\n",
    "config.motion_fc_out.temporal_fc = args.temporal_only\n",
    "config.motion_mlp.norm_axis = args.layer_norm_axis\n",
    "config.motion_mlp.spatial_fc_only = args.spatial_fc\n",
    "config.motion_mlp.with_normalization = args.with_normalization\n",
    "config.motion_mlp.num_layers = args.num\n",
    "\n",
    "# config.motion_rnn.with_normalization = args.with_normalization\n",
    "\n",
    "acc_log.write(''.join('Seed : ' + str(args.seed) + '\\n'))\n",
    "\n",
    "def get_dct_matrix(N):\n",
    "\tdct_m = np.eye(N)\n",
    "\tfor k in np.arange(N):\n",
    "\t\tfor i in np.arange(N):\n",
    "\t\t\tw = np.sqrt(2 / N)\n",
    "\t\t\tif k == 0:\n",
    "\t\t\t\tw = np.sqrt(1 / N)\n",
    "\t\t\tdct_m[k, i] = w * np.cos(np.pi * (i + 1 / 2) * k / N)\n",
    "\tidct_m = np.linalg.inv(dct_m)\n",
    "\treturn dct_m, idct_m\n",
    "\n",
    "# size: (1,T,T)\n",
    "dct_m,idct_m = get_dct_matrix(config.motion.h36m_input_length_dct)\n",
    "dct_m = torch.tensor(dct_m).float().cuda().unsqueeze(0)\n",
    "idct_m = torch.tensor(idct_m).float().cuda().unsqueeze(0)\n",
    "\n",
    "def update_lr_multistep(nb_iter, total_iter, max_lr, min_lr, optimizer) :\n",
    "\tif nb_iter < 10000:\n",
    "\t\tcurrent_lr = max_lr\n",
    "\telif nb_iter < 30000:\n",
    "\t\tcurrent_lr = mid_lr\n",
    "\telse:\n",
    "\t\tcurrent_lr = min_lr\n",
    "\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\tparam_group[\"lr\"] = current_lr\n",
    "\n",
    "\treturn optimizer, current_lr\n",
    "\n",
    "def gen_velocity(m):\n",
    "\tdm = m[:, 1:] - m[:, :-1]\n",
    "\treturn dm\n",
    "\n",
    "def train_step(h36m_motion_input, h36m_motion_target, model, optimizer, nb_iter, total_iter, max_lr, mid_lr, min_lr) :\n",
    "\n",
    "\tif config.pre_dct:\n",
    "\t\tb,n,c = h36m_motion_input.shape\n",
    "\t\th36m_motion_input_ = h36m_motion_input.clone()\n",
    "\t\th36m_motion_input_ = torch.matmul(dct_m[:, :, :config.motion.h36m_input_length], h36m_motion_input_.cuda())\n",
    "\telse:\n",
    "\t\th36m_motion_input_ = h36m_motion_input.clone()\n",
    "\n",
    "\tmotion_pred = model(h36m_motion_input_.cuda())\n",
    "\n",
    "\tif config.post_dct:\n",
    "\t\tmotion_pred = torch.matmul(idct_m[:, :config.motion.h36m_input_length, :], motion_pred)\n",
    "\n",
    "\tif config.residual_output:\n",
    "\t\toffset = h36m_motion_input[:, -1:].cuda()\n",
    "\t\tmotion_pred = motion_pred[:, :config.motion.h36m_target_length] + offset\n",
    "\telse:\n",
    "\t\tmotion_pred = motion_pred[:, :config.motion.h36m_target_length]\n",
    "\n",
    "\t# calc losses\n",
    "\tb,n,c = h36m_motion_target.shape\n",
    "\tmotion_pred = motion_pred.reshape(b,n,22,3).reshape(-1,3)\n",
    "\th36m_motion_target = h36m_motion_target.cuda().reshape(b,n,22,3).reshape(-1,3)\n",
    "\tloss = torch.mean(torch.norm(motion_pred - h36m_motion_target, 2, 1))\n",
    "\t# add position loss and velocity loss\n",
    "\tif config.use_relative_loss:\n",
    "\t\tmotion_pred = motion_pred.reshape(b,n,22,3)\n",
    "\t\tdmotion_pred = gen_velocity(motion_pred)\n",
    "\t\tmotion_gt = h36m_motion_target.reshape(b,n,22,3)\n",
    "\t\tdmotion_gt = gen_velocity(motion_gt)\n",
    "\t\tdloss = torch.mean(torch.norm((dmotion_pred - dmotion_gt).reshape(-1,3), 2, 1))\n",
    "\t\tloss = loss + dloss\n",
    "\telse:\n",
    "\t\tloss = loss.mean()\n",
    "\n",
    "\twriter.add_scalar('Loss/angle', loss.detach().cpu().numpy(), nb_iter)\n",
    "\n",
    "\t# reset gradients\n",
    "\toptimizer.zero_grad()\n",
    "\t# compute gradients by backpropagation\n",
    "\tloss.backward()\n",
    "\t# update params\n",
    "\toptimizer.step()\n",
    "\toptimizer, current_lr = update_lr_multistep(nb_iter, total_iter, max_lr, mid_lr, min_lr, optimizer)\n",
    "\twriter.add_scalar('LR/train', current_lr, nb_iter)\n",
    "\n",
    "\treturn loss.item(), optimizer, current_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siMLPe_RNN(\n",
      "  (rnn): SlidingRNN(\n",
      "    (endecoder): GRU(66, 66, batch_first=True)\n",
      "    (temporal_fc1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (temporal_fc): Linear(in_features=10, out_features=1, bias=True)\n",
      "    (spatial_fc): Linear(in_features=66, out_features=66, bias=True)\n",
      "    (arr0): Rearrange('b n d -> b d n')\n",
      "    (spatial_norm): Identity()\n",
      "  )\n",
      ")\n",
      "\n",
      "Window size: 10\n",
      "State size: 66\n",
      "Total count of parameters: 31075\n",
      "Residual output?  False\n",
      "Use DCT?  False\n",
      "Using recursive residual? True\n",
      "Using LayerNorm? False\n",
      "Using spatial fc before temporal in RNN? True\n",
      "Temporal layer in RNN: 1\n"
     ]
    }
   ],
   "source": [
    "test_window_size=10\n",
    "test_state_size=int(config.motion.dim)\n",
    "\n",
    "if config.model == 'siMLPe':\n",
    "\tmodel = models.siMLPe(config)\n",
    "elif config.model == 'siMLPe_RNN':\n",
    "\tmodel = models.siMLPe_RNN(config, rnn_state_size=test_state_size, rnn_layers=config.motion_rnn.num_layers, num_blocks=config.motion_rnn.num_blocks, window_size=test_window_size)\n",
    "elif config.model == 'Seq2SeqGRU':\n",
    "\tmodel = models.Seq2SeqGRU(config, state_size=test_state_size, num_layers=config.motion_rnn.num_layers)\n",
    "\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(\"Window size:\",test_window_size)\n",
    "print(\"State size:\",test_state_size)\n",
    "print(\"Total count of parameters:\",total_params)\n",
    "print(\"Residual output? \",config.residual_output)\n",
    "print(\"Use DCT? \",config.pre_dct)\n",
    "print(\"Using recursive residual?\",config.motion_rnn.recursive_residual)\n",
    "print(\"Using LayerNorm?\",config.motion_rnn.with_normalization)\n",
    "print(\"Using spatial fc before temporal in RNN?\",config.motion_rnn.local_spatial_fc)\n",
    "print(\"Temporal layer in RNN:\",config.motion_rnn.num_temp_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/home/gjsk/siMLPe/exps/baseline_h36m/log/log_last.log': File exists\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "# dataset = (T-by-C x_in, N-by-C x_out)\n",
    "config.motion.h36m_target_length = config.motion.h36m_target_length_train\n",
    "dataset = H36MDataset(config, 'train', config.data_aug)\n",
    "\n",
    "# separate into batches (input, target) with size (batch_size,T,C) and (batch_size,N,C)\n",
    "shuffle = True\n",
    "sampler = None\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size,\n",
    "\t\t\t\t\t\tnum_workers=config.num_workers, drop_last=True,\n",
    "\t\t\t\t\t\tsampler=sampler, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "eval_config = copy.deepcopy(config)\n",
    "eval_config.motion.h36m_target_length = eval_config.motion.h36m_target_length_eval\n",
    "eval_dataset = H36MEval(eval_config, 'test')\n",
    "\n",
    "shuffle = False\n",
    "sampler = None\n",
    "# separate into batches (input, target) with size (batch_size,T=50,K,3) and (batch_size,N=25,K,3)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=128,\n",
    "\t\t\t\t\t\tnum_workers=1, drop_last=False,\n",
    "\t\t\t\t\t\tsampler=sampler, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "\t\t\t\t\t\t\t lr=config.cos_lr_max,\n",
    "\t\t\t\t\t\t\t weight_decay=config.weight_decay)\n",
    "\n",
    "ensure_dir(config.snapshot_dir)\n",
    "logger = get_logger(config.log_file, 'train')\n",
    "link_file(config.log_file, config.link_log_file)\n",
    "\n",
    "print_and_log_info(logger, json.dumps(config, indent=4, sort_keys=True))\n",
    "\n",
    "# continue training from a checkpoint\n",
    "if config.model_pth is not None :\n",
    "\tstate_dict = torch.load(config.model_pth)\n",
    "\tmodel.load_state_dict(state_dict, strict=True)\n",
    "\tprint_and_log_info(logger, \"Loading model path from {} \".format(config.model_pth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter number: 688\n",
      "Iter number: 1376\n",
      "[np.float64(17.5), np.float64(34.4), np.float64(63.6), np.float64(75.5), np.float64(94.7), np.float64(108.4), np.float64(119.7), np.float64(127.0)]\n",
      "[-6.3, -10.0, -12.5, -12.7, -12.7, -13.2, -11.9, -9.6]\n",
      "Iter number: 2064\n",
      "Iter number: 2752\n",
      "[np.float64(16.5), np.float64(32.9), np.float64(62.0), np.float64(74.0), np.float64(93.2), np.float64(106.8), np.float64(117.9), np.float64(125.1)]\n",
      "[-7.3, -11.5, -14.1, -14.2, -14.2, -14.8, -13.7, -11.5]\n",
      "Iter number: 3440\n",
      "Iter number: 4128\n",
      "[np.float64(16.2), np.float64(32.5), np.float64(61.5), np.float64(73.6), np.float64(92.9), np.float64(107.1), np.float64(119.0), np.float64(126.5)]\n",
      "[-7.6, -11.9, -14.6, -14.6, -14.5, -14.5, -12.6, -10.1]\n",
      "Iter number: 4816\n",
      "Iter number: 5504\n",
      "[np.float64(15.9), np.float64(32.1), np.float64(61.1), np.float64(73.3), np.float64(92.9), np.float64(106.8), np.float64(118.4), np.float64(126.0)]\n",
      "[-7.9, -12.3, -15.0, -14.9, -14.5, -14.8, -13.2, -10.6]\n",
      "Iter number: 6192\n",
      "Iter number: 6880\n",
      "[np.float64(15.8), np.float64(31.9), np.float64(60.8), np.float64(73.1), np.float64(92.8), np.float64(107.0), np.float64(119.1), np.float64(126.8)]\n",
      "[-8.0, -12.5, -15.3, -15.1, -14.6, -14.6, -12.5, -9.8]\n",
      "Iter number: 7568\n",
      "Iter number: 8256\n",
      "Iter number: 8944\n",
      "[np.float64(15.6), np.float64(31.7), np.float64(60.8), np.float64(73.5), np.float64(93.9), np.float64(108.6), np.float64(121.0), np.float64(128.8)]\n",
      "[-8.2, -12.7, -15.3, -14.7, -13.5, -13.0, -10.6, -7.8]\n",
      "Iter number: 9632\n",
      "Iter number: 10320\n",
      "[np.float64(15.5), np.float64(31.6), np.float64(60.5), np.float64(72.9), np.float64(92.8), np.float64(107.2), np.float64(119.4), np.float64(127.0)]\n",
      "[-8.3, -12.8, -15.6, -15.3, -14.6, -14.4, -12.2, -9.6]\n",
      "Iter number: 11008\n",
      "Iter number: 11696\n",
      "[np.float64(15.4), np.float64(31.3), np.float64(60.3), np.float64(73.0), np.float64(93.3), np.float64(108.1), np.float64(120.3), np.float64(127.7)]\n",
      "[-8.4, -13.1, -15.8, -15.2, -14.1, -13.5, -11.3, -8.9]\n",
      "Iter number: 12384\n",
      "Iter number: 13072\n",
      "[np.float64(15.3), np.float64(31.2), np.float64(60.1), np.float64(72.6), np.float64(92.7), np.float64(107.2), np.float64(119.4), np.float64(127.1)]\n",
      "[-8.5, -13.2, -16.0, -15.6, -14.7, -14.4, -12.2, -9.5]\n",
      "Iter number: 13760\n",
      "Iter number: 14448\n",
      "[np.float64(15.2), np.float64(31.1), np.float64(59.9), np.float64(72.4), np.float64(92.6), np.float64(107.3), np.float64(119.8), np.float64(127.7)]\n",
      "[-8.6, -13.3, -16.2, -15.8, -14.8, -14.3, -11.8, -8.9]\n",
      "Iter number: 15136\n",
      "Iter number: 15824\n",
      "[np.float64(15.1), np.float64(30.9), np.float64(59.4), np.float64(71.7), np.float64(91.4), np.float64(105.7), np.float64(117.8), np.float64(125.3)]\n",
      "[-8.7, -13.5, -16.7, -16.5, -16.0, -15.9, -13.8, -11.3]\n",
      "Iter number: 16512\n",
      "Iter number: 17200\n",
      "Iter number: 17888\n",
      "[np.float64(15.0), np.float64(30.9), np.float64(59.5), np.float64(71.9), np.float64(91.7), np.float64(106.4), np.float64(118.7), np.float64(126.3)]\n",
      "[-8.8, -13.5, -16.6, -16.3, -15.7, -15.2, -12.9, -10.3]\n",
      "Iter number: 18576\n",
      "Iter number: 19264\n",
      "[np.float64(15.0), np.float64(31.0), np.float64(59.6), np.float64(72.0), np.float64(91.8), np.float64(106.3), np.float64(118.6), np.float64(126.5)]\n",
      "[-8.8, -13.4, -16.5, -16.2, -15.6, -15.3, -13.0, -10.1]\n",
      "Iter number: 19952\n",
      "Iter number: 19999\n"
     ]
    }
   ],
   "source": [
    "nb_iter = 0\n",
    "avg_loss = 0\n",
    "avg_lr = 0\n",
    "current_lr = config.cos_lr_max\n",
    "\n",
    "config.save_every = 1500\n",
    "config.cos_lr_total_iters = 19500\n",
    "baseline_results = [23.8,44.4,76.1,88.2,107.4,121.6,131.6,136.6]\n",
    "\n",
    "# about 1 min per 1000 iterations\n",
    "while (nb_iter + 1) < config.cos_lr_total_iters:\n",
    "\n",
    "\tfor (h36m_motion_input, h36m_motion_target) in dataloader:\n",
    "\n",
    "\t\tloss, optimizer, current_lr = train_step(h36m_motion_input, h36m_motion_target, model, optimizer, nb_iter, config.cos_lr_total_iters, config.cos_lr_max, config.cos_lr_mid, config.cos_lr_min)\n",
    "\t\tavg_loss += loss\n",
    "\t\tavg_lr += current_lr\n",
    "\n",
    "\t\tif (nb_iter + 1) % config.print_every ==  0 :\n",
    "\t\t\tavg_loss = avg_loss / config.print_every\n",
    "\t\t\tavg_lr = avg_lr / config.print_every\n",
    "\n",
    "\t\t\tprint_and_log_info(logger, \"Iter {} Summary: \".format(nb_iter + 1))\n",
    "\t\t\tprint_and_log_info(logger, f\"\\t lr: {avg_lr} \\t Training loss: {avg_loss}\")\n",
    "\t\t\tavg_loss = 0\n",
    "\t\t\tavg_lr = 0\n",
    "\n",
    "\t\tif (nb_iter + 1) % config.save_every ==  0 :\n",
    "\t\t\ttorch.save(model.state_dict(), config.snapshot_dir + '/model-iter-' + str(nb_iter + 1) + '.pth')\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tacc_tmp = test(eval_config, model, eval_dataloader)\n",
    "\t\t\tprint(acc_tmp)\n",
    "\t\t\tprint([round(float(acc_tmp[i]-baseline_results[i]),2) for i in range(8)])\n",
    "\t\t\tacc_log.write(''.join(str(nb_iter + 1) + '\\n'))\n",
    "\t\t\tline = ''\n",
    "\t\t\tfor ii in acc_tmp:\n",
    "\t\t\t\tline += str(ii) + ' '\n",
    "\t\t\tline += '\\n'\n",
    "\t\t\tacc_log.write(''.join(line))\n",
    "\t\t\tmodel.train()\n",
    "\n",
    "\t\tif (nb_iter + 1) == config.cos_lr_total_iters :\n",
    "\t\t\tbreak\n",
    "\t\tnb_iter += 1\n",
    "\tprint(\"Iter number:\",nb_iter)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "arr0 = Rearrange('b n d -> b d n')\n",
    "arr1 = Rearrange('b d n -> b n d')\n",
    "\n",
    "nb_iter = 0\n",
    "avg_loss = 0\n",
    "avg_lr = 0\n",
    "\n",
    "(h36m_motion_input, h36m_motion_target) = next(iter(dataloader))\n",
    "\n",
    "# loss, optimizer, current_lr = train_step(h36m_motion_input, h36m_motion_target, model, optimizer, nb_iter, config.cos_lr_total_iters, config.cos_lr_max, config.cos_lr_min)\n",
    "# train_step(h36m_motion_input, h36m_motion_target, model, optimizer, nb_iter, total_iter, max_lr, min_lr)\n",
    "total_iter, max_lr, min_lr = config.cos_lr_total_iters, config.cos_lr_max, config.cos_lr_min\n",
    "\n",
    "# DCT\n",
    "b,n,c = h36m_motion_input.shape\n",
    "h36m_motion_input_ = h36m_motion_input.clone()\n",
    "h36m_motion_input_ = torch.matmul(dct_m[:, :, :config.motion.h36m_input_length], h36m_motion_input_.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as models\n",
    "# model = models.siMLPe_RNN(config, rnn_state_size=int(config.motion.dim*1.5), rnn_layers=config.motion_rnn.num_layers, num_blocks=config.motion_rnn.num_blocks).cuda()\n",
    "test_model = models.SlidingGRU(config, state_size=int(config.motion.dim), num_layers=config.motion_rnn.num_layers, window_size=5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (5) at non-singleton dimension 1.  Target sizes: [256, 1, 66].  Tensor sizes: [256, 5, 66]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m \t\u001b[38;5;66;03m# Residual method 2 (residual from the last input frame):\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \tnew_frame \u001b[38;5;241m=\u001b[39m test_model\u001b[38;5;241m.\u001b[39mspatial_norm(_decoder_out) \u001b[38;5;241m+\u001b[39m last_input_frame\n\u001b[0;32m---> 37\u001b[0m \u001b[43moutput_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_id\u001b[49m\u001b[43m:\u001b[49m\u001b[43mframe_id\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m new_frame\n\u001b[1;32m     38\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m new_frame  \u001b[38;5;66;03m# Next input is current output\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (5) at non-singleton dimension 1.  Target sizes: [256, 1, 66].  Tensor sizes: [256, 5, 66]"
     ]
    }
   ],
   "source": [
    "# motion_pred = model(h36m_motion_input_.cuda())\n",
    "x = h36m_motion_input_.cuda()\n",
    "\n",
    "B, T, C = x.size()\n",
    "assert(C == test_model.config.motion.dim)\n",
    "\n",
    "# Encoder: start with zero hidden states\n",
    "encoder_out, rnn_states = test_model.endecoder(x)  # hidden: [num_layers, B, state_size]\n",
    "\n",
    "# Decoder initialization\n",
    "last_input_frame = x[:, -1:, :]  # Last time step of input as initial input [B, 1, C]\n",
    "decoder_input = last_input_frame.clone()\n",
    "\n",
    "# size = [B, window_size, state_size]\n",
    "encoder_window = encoder_out[:, -test_model.window_size:, :]\n",
    "\n",
    "output_frames = torch.zeros(B, T, C).cuda()\n",
    "for frame_id in range(T):\n",
    "\t# Decoder: # [B, 1, C]\n",
    "\tdecoder_out, rnn_states = test_model.endecoder(decoder_input, rnn_states)\n",
    "\n",
    "\t# Sliding window\n",
    "\tencoder_window = torch.cat([encoder_window[:, 1:, :], decoder_out], dim=1)\n",
    "\t_decoder_out = test_model.arr0(test_model.temporal_fc(test_model.arr0(encoder_window)))\n",
    "\t_decoder_out = test_model.spatial_fc(_decoder_out)\n",
    "\n",
    "\t# decoder_out = test_model.temporal_fc(decoder_out)  # [B, 1, C]\n",
    "\t# decoder_out = test_model.fc1(decoder_out) + decoder_out  # [B, 1, C]\n",
    "\n",
    "\tif test_model.config.motion_rnn.recursive_residual:\n",
    "\t\t# Residual method 1 (recursive residual; same as in 2017 Martinez paper):\n",
    "\t\tnew_frame = test_model.spatial_norm(_decoder_out) + decoder_input\n",
    "\telse:\n",
    "\t\t# Residual method 2 (residual from the last input frame):\n",
    "\t\tnew_frame = test_model.spatial_norm(_decoder_out) + last_input_frame\n",
    "\n",
    "\toutput_frames[:, frame_id:frame_id+1, :] = new_frame\n",
    "\tdecoder_input = new_frame  # Next input is current output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 5, 66])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_decoder_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDCT\n",
    "motion_pred = torch.matmul(idct_m[:, :config.motion.h36m_input_length, :], motion_pred)\n",
    "\n",
    "# add residual\n",
    "if config.residual_output:\n",
    "\toffset = h36m_motion_input[:, -1:].cuda()\n",
    "\tmotion_pred = motion_pred[:, :config.motion.h36m_target_length] + offset\n",
    "else:\n",
    "\tmotion_pred = motion_pred[:, :config.motion.h36m_target_length]\n",
    "\n",
    "# calc losses\n",
    "b,n,c = h36m_motion_target.shape\n",
    "motion_pred = motion_pred.reshape(b,n,22,3).reshape(-1,3)\n",
    "h36m_motion_target = h36m_motion_target.cuda().reshape(b,n,22,3).reshape(-1,3)\n",
    "loss = torch.mean(torch.norm(motion_pred - h36m_motion_target, 2, 1))\n",
    "# add position loss and velocity loss\n",
    "if config.use_relative_loss:\n",
    "\tmotion_pred = motion_pred.reshape(b,n,22,3)\n",
    "\tdmotion_pred = gen_velocity(motion_pred)\n",
    "\tmotion_gt = h36m_motion_target.reshape(b,n,22,3)\n",
    "\tdmotion_gt = gen_velocity(motion_gt)\n",
    "\tdloss = torch.mean(torch.norm((dmotion_pred - dmotion_gt).reshape(-1,3), 2, 1))\n",
    "\tloss = loss + dloss\n",
    "else:\n",
    "\tloss = loss.mean()\n",
    "\n",
    "writer.add_scalar('Loss/angle', loss.detach().cpu().numpy(), nb_iter)\n",
    "\n",
    "# reset gradients\n",
    "optimizer.zero_grad()\n",
    "# compute gradients by backpropagation\n",
    "loss.backward()\n",
    "# update params\n",
    "optimizer.step()\n",
    "optimizer, current_lr = update_lr_multistep(nb_iter, total_iter, max_lr, min_lr, optimizer)\n",
    "writer.add_scalar('LR/train', current_lr, nb_iter)\n",
    "\n",
    "return loss.item(), optimizer, current_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syde_675",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
