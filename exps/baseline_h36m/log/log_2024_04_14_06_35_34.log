[2024-04-14 06:35:42,071] INFO: {
    "abs_dir": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m",
    "batch_size": 256,
    "cos_lr_max": 1e-05,
    "cos_lr_min": 5e-08,
    "cos_lr_total_iters": 40000,
    "data_aug": true,
    "deriv_input": true,
    "deriv_output": true,
    "h36m_anno_dir": "/Users/macair/Desktop/siMLPe/data/h36m/",
    "link_log_file": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log/log_last.log",
    "link_val_log_file": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log/val_last.log",
    "log_dir": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log",
    "log_file": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log/log_2024_04_14_06_35_34.log",
    "model_pth": null,
    "motion": {
        "dim": 66,
        "h36m_input_length": 50,
        "h36m_input_length_dct": 50,
        "h36m_target_length": 10,
        "h36m_target_length_eval": 25,
        "h36m_target_length_train": 10
    },
    "motion_fc_in": {
        "activation": "relu",
        "in_features": 66,
        "init_w_trunc_normal": false,
        "out_features": 66,
        "temporal_fc": false,
        "with_norm": false
    },
    "motion_fc_out": {
        "activation": "relu",
        "in_features": 66,
        "init_w_trunc_normal": true,
        "out_features": 66,
        "temporal_fc": false,
        "with_norm": false
    },
    "motion_mlp": {
        "hidden_dim": 66,
        "norm_axis": "spatial",
        "num_layers": 48,
        "seq_len": 50,
        "spatial_fc_only": false,
        "with_normalization": true
    },
    "num_workers": 0,
    "post_dct": false,
    "pre_dct": false,
    "print_every": 100,
    "repo_name": "siMLPe",
    "root_dir": "/Users/macair/Desktop/siMLPe",
    "save_every": 5000,
    "seed": 304,
    "shift_step": 1,
    "snapshot_dir": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log/snapshot",
    "this_dir": "baseline_h36m",
    "use_relative_loss": true,
    "val_log_file": "/Users/macair/Desktop/siMLPe/exps/baseline_h36m/log/val_2024_04_14_06_35_34.log",
    "weight_decay": 0.0001
}
[2024-04-14 06:36:20,149] INFO: Iter 100 Summary: 
[2024-04-14 06:36:20,150] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0931885989010334
[2024-04-14 06:36:58,393] INFO: Iter 200 Summary: 
[2024-04-14 06:36:58,393] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.07497534327208996
[2024-04-14 06:37:37,293] INFO: Iter 300 Summary: 
[2024-04-14 06:37:37,294] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.07549458786845208
[2024-04-14 06:38:15,047] INFO: Iter 400 Summary: 
[2024-04-14 06:38:15,048] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.07450047433376313
[2024-04-14 06:38:52,962] INFO: Iter 500 Summary: 
[2024-04-14 06:38:52,962] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.07083379901945591
[2024-04-14 06:39:30,652] INFO: Iter 600 Summary: 
[2024-04-14 06:39:30,652] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.06774762220680713
[2024-04-14 06:40:08,473] INFO: Iter 700 Summary: 
[2024-04-14 06:40:08,473] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.06243326123803854
[2024-04-14 06:40:45,830] INFO: Iter 800 Summary: 
[2024-04-14 06:40:45,830] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05910033129155636
[2024-04-14 06:41:23,224] INFO: Iter 900 Summary: 
[2024-04-14 06:41:23,224] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.057508445158600804
[2024-04-14 06:42:00,658] INFO: Iter 1000 Summary: 
[2024-04-14 06:42:00,658] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.057248796969652176
[2024-04-14 06:42:37,916] INFO: Iter 1100 Summary: 
[2024-04-14 06:42:37,916] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05645172733813524
[2024-04-14 06:43:15,123] INFO: Iter 1200 Summary: 
[2024-04-14 06:43:15,123] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05589426130056381
[2024-04-14 06:43:51,845] INFO: Iter 1300 Summary: 
[2024-04-14 06:43:51,845] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05528202272951603
[2024-04-14 06:44:27,952] INFO: Iter 1400 Summary: 
[2024-04-14 06:44:27,952] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0549847025424242
[2024-04-14 06:45:05,134] INFO: Iter 1500 Summary: 
[2024-04-14 06:45:05,134] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.054475134946405886
[2024-04-14 06:45:43,398] INFO: Iter 1600 Summary: 
[2024-04-14 06:45:43,398] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05387201841920614
[2024-04-14 06:46:21,419] INFO: Iter 1700 Summary: 
[2024-04-14 06:46:21,419] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05387620802968741
[2024-04-14 06:46:59,563] INFO: Iter 1800 Summary: 
[2024-04-14 06:46:59,563] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05297088406980038
[2024-04-14 06:47:37,442] INFO: Iter 1900 Summary: 
[2024-04-14 06:47:37,442] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.053067243471741674
[2024-04-14 06:48:14,992] INFO: Iter 2000 Summary: 
[2024-04-14 06:48:14,992] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05226938523352146
[2024-04-14 06:48:53,067] INFO: Iter 2100 Summary: 
[2024-04-14 06:48:53,067] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.052419001124799254
[2024-04-14 06:49:31,314] INFO: Iter 2200 Summary: 
[2024-04-14 06:49:31,314] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.052470657415688036
[2024-04-14 06:50:09,529] INFO: Iter 2300 Summary: 
[2024-04-14 06:50:09,529] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.052118330858647824
[2024-04-14 06:50:47,821] INFO: Iter 2400 Summary: 
[2024-04-14 06:50:47,821] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.051591593883931634
[2024-04-14 06:51:26,269] INFO: Iter 2500 Summary: 
[2024-04-14 06:51:26,269] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05180180750787258
[2024-04-14 06:52:05,158] INFO: Iter 2600 Summary: 
[2024-04-14 06:52:05,158] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05165836401283741
[2024-04-14 06:52:43,715] INFO: Iter 2700 Summary: 
[2024-04-14 06:52:43,715] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05163339104503393
[2024-04-14 06:53:22,366] INFO: Iter 2800 Summary: 
[2024-04-14 06:53:22,366] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05131395075470209
[2024-04-14 06:54:01,048] INFO: Iter 2900 Summary: 
[2024-04-14 06:54:01,048] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05108378857374191
[2024-04-14 06:54:39,654] INFO: Iter 3000 Summary: 
[2024-04-14 06:54:39,654] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.050958705954253676
[2024-04-14 06:55:18,489] INFO: Iter 3100 Summary: 
[2024-04-14 06:55:18,489] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.051211731992661956
[2024-04-14 06:55:57,267] INFO: Iter 3200 Summary: 
[2024-04-14 06:55:57,267] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.051136641427874566
[2024-04-14 06:56:35,979] INFO: Iter 3300 Summary: 
[2024-04-14 06:56:35,979] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05017634879797697
[2024-04-14 06:57:14,883] INFO: Iter 3400 Summary: 
[2024-04-14 06:57:14,884] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.050424113273620605
[2024-04-14 06:57:53,893] INFO: Iter 3500 Summary: 
[2024-04-14 06:57:53,893] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05059573955833912
[2024-04-14 06:58:36,396] INFO: Iter 3600 Summary: 
[2024-04-14 06:58:36,396] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.050131108537316324
[2024-04-14 06:59:18,781] INFO: Iter 3700 Summary: 
[2024-04-14 06:59:18,781] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05007814586162567
[2024-04-14 07:00:01,823] INFO: Iter 3800 Summary: 
[2024-04-14 07:00:01,824] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.05012188620865345
[2024-04-14 07:00:44,822] INFO: Iter 3900 Summary: 
[2024-04-14 07:00:44,822] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04956386275589466
[2024-04-14 07:01:27,451] INFO: Iter 4000 Summary: 
[2024-04-14 07:01:27,451] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04973862197250128
[2024-04-14 07:02:09,905] INFO: Iter 4100 Summary: 
[2024-04-14 07:02:09,905] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.049601212218403815
[2024-04-14 07:02:52,849] INFO: Iter 4200 Summary: 
[2024-04-14 07:02:52,849] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04958751678466797
[2024-04-14 07:03:35,843] INFO: Iter 4300 Summary: 
[2024-04-14 07:03:35,843] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.049144771806895735
[2024-04-14 07:04:18,590] INFO: Iter 4400 Summary: 
[2024-04-14 07:04:18,590] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04915456052869558
[2024-04-14 07:05:01,472] INFO: Iter 4500 Summary: 
[2024-04-14 07:05:01,472] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.049370594918727875
[2024-04-14 07:05:44,453] INFO: Iter 4600 Summary: 
[2024-04-14 07:05:44,453] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.049056943021714684
[2024-04-14 07:06:27,259] INFO: Iter 4700 Summary: 
[2024-04-14 07:06:27,259] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04908540543168783
[2024-04-14 07:07:10,205] INFO: Iter 4800 Summary: 
[2024-04-14 07:07:10,205] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04864340182393789
[2024-04-14 07:07:52,595] INFO: Iter 4900 Summary: 
[2024-04-14 07:07:52,595] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04861265230923891
[2024-04-14 07:08:35,252] INFO: Iter 5000 Summary: 
[2024-04-14 07:08:35,252] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04881203476339579
[2024-04-14 07:09:17,855] INFO: Iter 5100 Summary: 
[2024-04-14 07:09:17,855] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.048586655408144
[2024-04-14 07:10:01,205] INFO: Iter 5200 Summary: 
[2024-04-14 07:10:01,205] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04812883924692869
[2024-04-14 07:10:44,221] INFO: Iter 5300 Summary: 
[2024-04-14 07:10:44,222] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.048413668535649775
[2024-04-14 07:11:26,850] INFO: Iter 5400 Summary: 
[2024-04-14 07:11:26,850] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04825125437229872
[2024-04-14 07:12:09,251] INFO: Iter 5500 Summary: 
[2024-04-14 07:12:09,252] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0479869494959712
[2024-04-14 07:12:52,158] INFO: Iter 5600 Summary: 
[2024-04-14 07:12:52,158] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04801686391234398
[2024-04-14 07:13:35,240] INFO: Iter 5700 Summary: 
[2024-04-14 07:13:35,240] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04807576298713684
[2024-04-14 07:14:18,157] INFO: Iter 5800 Summary: 
[2024-04-14 07:14:18,157] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.047895833291113375
[2024-04-14 07:15:01,117] INFO: Iter 5900 Summary: 
[2024-04-14 07:15:01,117] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04775832518935204
[2024-04-14 07:15:44,125] INFO: Iter 6000 Summary: 
[2024-04-14 07:15:44,125] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.047606374509632586
[2024-04-14 07:16:27,192] INFO: Iter 6100 Summary: 
[2024-04-14 07:16:27,192] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04729360740631819
[2024-04-14 07:17:10,412] INFO: Iter 6200 Summary: 
[2024-04-14 07:17:10,412] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04719951566308737
[2024-04-14 07:17:53,337] INFO: Iter 6300 Summary: 
[2024-04-14 07:17:53,337] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04747579224407673
[2024-04-14 07:18:36,204] INFO: Iter 6400 Summary: 
[2024-04-14 07:18:36,204] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.047110367827117444
[2024-04-14 07:19:19,415] INFO: Iter 6500 Summary: 
[2024-04-14 07:19:19,415] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04684939213097095
[2024-04-14 07:20:02,555] INFO: Iter 6600 Summary: 
[2024-04-14 07:20:02,555] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.047262241430580616
[2024-04-14 07:20:45,717] INFO: Iter 6700 Summary: 
[2024-04-14 07:20:45,717] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.046961711421608925
[2024-04-14 07:21:28,724] INFO: Iter 6800 Summary: 
[2024-04-14 07:21:28,725] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.046863193958997726
[2024-04-14 07:22:11,903] INFO: Iter 6900 Summary: 
[2024-04-14 07:22:11,903] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0473745796084404
[2024-04-14 07:22:55,129] INFO: Iter 7000 Summary: 
[2024-04-14 07:22:55,129] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04663784358650446
[2024-04-14 07:23:38,618] INFO: Iter 7100 Summary: 
[2024-04-14 07:23:38,618] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.046373156756162645
[2024-04-14 07:24:21,937] INFO: Iter 7200 Summary: 
[2024-04-14 07:24:21,937] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0469386337697506
[2024-04-14 07:25:05,506] INFO: Iter 7300 Summary: 
[2024-04-14 07:25:05,506] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.046531905345618726
[2024-04-14 07:25:48,972] INFO: Iter 7400 Summary: 
[2024-04-14 07:25:48,972] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0464910389110446
[2024-04-14 07:26:32,276] INFO: Iter 7500 Summary: 
[2024-04-14 07:26:32,276] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04580611679702997
[2024-04-14 07:27:15,979] INFO: Iter 7600 Summary: 
[2024-04-14 07:27:15,979] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04575764514505863
[2024-04-14 07:28:00,217] INFO: Iter 7700 Summary: 
[2024-04-14 07:28:00,217] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04649729337543249
[2024-04-14 07:28:43,385] INFO: Iter 7800 Summary: 
[2024-04-14 07:28:43,385] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.045916331596672535
[2024-04-14 07:29:26,351] INFO: Iter 7900 Summary: 
[2024-04-14 07:29:26,351] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04630330137908459
[2024-04-14 07:30:09,469] INFO: Iter 8000 Summary: 
[2024-04-14 07:30:09,469] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04595013823360205
[2024-04-14 07:30:52,946] INFO: Iter 8100 Summary: 
[2024-04-14 07:30:52,946] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04598598949611187
[2024-04-14 07:31:36,018] INFO: Iter 8200 Summary: 
[2024-04-14 07:31:36,018] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.045606349036097525
[2024-04-14 07:32:18,840] INFO: Iter 8300 Summary: 
[2024-04-14 07:32:18,841] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04550730526447296
[2024-04-14 07:33:01,564] INFO: Iter 8400 Summary: 
[2024-04-14 07:33:01,565] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04537079375237227
[2024-04-14 07:33:44,307] INFO: Iter 8500 Summary: 
[2024-04-14 07:33:44,307] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04570388197898865
[2024-04-14 07:34:27,134] INFO: Iter 8600 Summary: 
[2024-04-14 07:34:27,134] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04564151290804148
[2024-04-14 07:35:10,086] INFO: Iter 8700 Summary: 
[2024-04-14 07:35:10,086] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04510479912161827
[2024-04-14 07:35:53,170] INFO: Iter 8800 Summary: 
[2024-04-14 07:35:53,170] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04563687283545732
[2024-04-14 07:36:36,117] INFO: Iter 8900 Summary: 
[2024-04-14 07:36:36,117] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.045478687696158884
[2024-04-14 07:37:19,206] INFO: Iter 9000 Summary: 
[2024-04-14 07:37:19,206] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04495435327291489
[2024-04-14 07:38:02,205] INFO: Iter 9100 Summary: 
[2024-04-14 07:38:02,205] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.045120318233966825
[2024-04-14 07:38:45,300] INFO: Iter 9200 Summary: 
[2024-04-14 07:38:45,300] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04516189143061638
[2024-04-14 07:39:28,659] INFO: Iter 9300 Summary: 
[2024-04-14 07:39:28,659] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.045207947827875614
[2024-04-14 07:40:11,628] INFO: Iter 9400 Summary: 
[2024-04-14 07:40:11,628] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044823922701179984
[2024-04-14 07:40:54,751] INFO: Iter 9500 Summary: 
[2024-04-14 07:40:54,751] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04458262838423252
[2024-04-14 07:41:38,081] INFO: Iter 9600 Summary: 
[2024-04-14 07:41:38,081] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04491599906235933
[2024-04-14 07:42:21,398] INFO: Iter 9700 Summary: 
[2024-04-14 07:42:21,398] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04474356446415186
[2024-04-14 07:43:04,608] INFO: Iter 9800 Summary: 
[2024-04-14 07:43:04,608] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04486990835517645
[2024-04-14 07:43:48,070] INFO: Iter 9900 Summary: 
[2024-04-14 07:43:48,070] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04435996633023023
[2024-04-14 07:44:31,600] INFO: Iter 10000 Summary: 
[2024-04-14 07:44:31,600] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04469919595867396
[2024-04-14 07:45:14,626] INFO: Iter 10100 Summary: 
[2024-04-14 07:45:14,626] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04467638898640871
[2024-04-14 07:45:57,404] INFO: Iter 10200 Summary: 
[2024-04-14 07:45:57,404] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0444070564955473
[2024-04-14 07:46:40,172] INFO: Iter 10300 Summary: 
[2024-04-14 07:46:40,172] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04464146088808775
[2024-04-14 07:47:23,291] INFO: Iter 10400 Summary: 
[2024-04-14 07:47:23,291] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044390631355345246
[2024-04-14 07:48:06,063] INFO: Iter 10500 Summary: 
[2024-04-14 07:48:06,063] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044259431026875976
[2024-04-14 07:48:48,931] INFO: Iter 10600 Summary: 
[2024-04-14 07:48:48,931] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044091547764837744
[2024-04-14 07:49:31,602] INFO: Iter 10700 Summary: 
[2024-04-14 07:49:31,602] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044123418629169464
[2024-04-14 07:50:14,833] INFO: Iter 10800 Summary: 
[2024-04-14 07:50:14,833] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04408113863319159
[2024-04-14 07:50:57,717] INFO: Iter 10900 Summary: 
[2024-04-14 07:50:57,717] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04442330714315176
[2024-04-14 07:51:40,439] INFO: Iter 11000 Summary: 
[2024-04-14 07:51:40,439] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04394013773649931
[2024-04-14 07:52:23,265] INFO: Iter 11100 Summary: 
[2024-04-14 07:52:23,265] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04402604226022959
[2024-04-14 07:53:06,115] INFO: Iter 11200 Summary: 
[2024-04-14 07:53:06,115] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04390405960381031
[2024-04-14 07:53:48,971] INFO: Iter 11300 Summary: 
[2024-04-14 07:53:48,971] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.044062928073108194
[2024-04-14 07:54:31,941] INFO: Iter 11400 Summary: 
[2024-04-14 07:54:31,941] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04392194271087647
[2024-04-14 07:55:15,029] INFO: Iter 11500 Summary: 
[2024-04-14 07:55:15,029] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043811839856207374
[2024-04-14 07:55:57,913] INFO: Iter 11600 Summary: 
[2024-04-14 07:55:57,913] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04382452450692654
[2024-04-14 07:56:41,180] INFO: Iter 11700 Summary: 
[2024-04-14 07:56:41,180] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043567794412374496
[2024-04-14 07:57:24,513] INFO: Iter 11800 Summary: 
[2024-04-14 07:57:24,513] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043435416929423806
[2024-04-14 07:58:07,195] INFO: Iter 11900 Summary: 
[2024-04-14 07:58:07,195] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043737688139081
[2024-04-14 07:58:50,123] INFO: Iter 12000 Summary: 
[2024-04-14 07:58:50,123] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04368527740240097
[2024-04-14 07:59:35,854] INFO: Iter 12100 Summary: 
[2024-04-14 07:59:35,854] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04357045687735081
[2024-04-14 08:00:22,859] INFO: Iter 12200 Summary: 
[2024-04-14 08:00:22,859] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04387569192796945
[2024-04-14 08:01:10,137] INFO: Iter 12300 Summary: 
[2024-04-14 08:01:10,137] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04333323169499636
[2024-04-14 08:01:57,562] INFO: Iter 12400 Summary: 
[2024-04-14 08:01:57,562] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04364222377538681
[2024-04-14 08:02:45,192] INFO: Iter 12500 Summary: 
[2024-04-14 08:02:45,192] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043390927650034425
[2024-04-14 08:03:32,602] INFO: Iter 12600 Summary: 
[2024-04-14 08:03:32,602] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04347030971199274
[2024-04-14 08:04:20,076] INFO: Iter 12700 Summary: 
[2024-04-14 08:04:20,076] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043250132128596304
[2024-04-14 08:05:05,710] INFO: Iter 12800 Summary: 
[2024-04-14 08:05:05,710] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.043397250697016714
[2024-04-14 08:05:50,133] INFO: Iter 12900 Summary: 
[2024-04-14 08:05:50,133] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04310081463307142
[2024-04-14 08:06:34,729] INFO: Iter 13000 Summary: 
[2024-04-14 08:06:34,729] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04325965743511915
[2024-04-14 08:07:18,622] INFO: Iter 13100 Summary: 
[2024-04-14 08:07:18,622] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04313026029616594
[2024-04-14 08:08:01,997] INFO: Iter 13200 Summary: 
[2024-04-14 08:08:01,997] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04322874393314123
[2024-04-14 08:08:45,762] INFO: Iter 13300 Summary: 
[2024-04-14 08:08:45,762] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04327276788651943
[2024-04-14 08:09:29,851] INFO: Iter 13400 Summary: 
[2024-04-14 08:09:29,851] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04309803061187267
[2024-04-14 08:10:13,521] INFO: Iter 13500 Summary: 
[2024-04-14 08:10:13,521] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04311411738395691
[2024-04-14 08:10:56,927] INFO: Iter 13600 Summary: 
[2024-04-14 08:10:56,927] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04262783590704203
[2024-04-14 08:11:40,379] INFO: Iter 13700 Summary: 
[2024-04-14 08:11:40,379] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0428306570276618
[2024-04-14 08:12:24,157] INFO: Iter 13800 Summary: 
[2024-04-14 08:12:24,157] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042707066610455514
[2024-04-14 08:13:07,918] INFO: Iter 13900 Summary: 
[2024-04-14 08:13:07,918] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04294509150087834
[2024-04-14 08:13:52,066] INFO: Iter 14000 Summary: 
[2024-04-14 08:13:52,066] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042967470698058605
[2024-04-14 08:14:35,796] INFO: Iter 14100 Summary: 
[2024-04-14 08:14:35,796] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04276360224932432
[2024-04-14 08:15:19,623] INFO: Iter 14200 Summary: 
[2024-04-14 08:15:19,623] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042929817289114
[2024-04-14 08:16:03,078] INFO: Iter 14300 Summary: 
[2024-04-14 08:16:03,078] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04279377050697804
[2024-04-14 08:16:46,828] INFO: Iter 14400 Summary: 
[2024-04-14 08:16:46,828] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04263251043856144
[2024-04-14 08:17:30,765] INFO: Iter 14500 Summary: 
[2024-04-14 08:17:30,765] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04266228284686804
[2024-04-14 08:18:14,715] INFO: Iter 14600 Summary: 
[2024-04-14 08:18:14,715] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042550862655043604
[2024-04-14 08:18:58,498] INFO: Iter 14700 Summary: 
[2024-04-14 08:18:58,498] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04247910853475332
[2024-04-14 08:19:42,373] INFO: Iter 14800 Summary: 
[2024-04-14 08:19:42,373] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042790751717984674
[2024-04-14 08:20:26,195] INFO: Iter 14900 Summary: 
[2024-04-14 08:20:26,195] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04228548727929592
[2024-04-14 08:21:10,699] INFO: Iter 15000 Summary: 
[2024-04-14 08:21:10,699] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04219131600111723
[2024-04-14 08:21:55,570] INFO: Iter 15100 Summary: 
[2024-04-14 08:21:55,570] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04295577969402075
[2024-04-14 08:22:39,226] INFO: Iter 15200 Summary: 
[2024-04-14 08:22:39,227] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04235223364084959
[2024-04-14 08:23:22,757] INFO: Iter 15300 Summary: 
[2024-04-14 08:23:22,757] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04202343713492155
[2024-04-14 08:24:06,698] INFO: Iter 15400 Summary: 
[2024-04-14 08:24:06,698] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042516639828681944
[2024-04-14 08:24:50,704] INFO: Iter 15500 Summary: 
[2024-04-14 08:24:50,705] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042599784955382344
[2024-04-14 08:25:34,906] INFO: Iter 15600 Summary: 
[2024-04-14 08:25:34,906] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042337715327739715
[2024-04-14 08:26:18,856] INFO: Iter 15700 Summary: 
[2024-04-14 08:26:18,856] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04226196963340044
[2024-04-14 08:27:02,859] INFO: Iter 15800 Summary: 
[2024-04-14 08:27:02,859] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04248974997550249
[2024-04-14 08:27:46,969] INFO: Iter 15900 Summary: 
[2024-04-14 08:27:46,969] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042379987873136994
[2024-04-14 08:28:31,121] INFO: Iter 16000 Summary: 
[2024-04-14 08:28:31,121] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042251689471304414
[2024-04-14 08:29:15,844] INFO: Iter 16100 Summary: 
[2024-04-14 08:29:15,844] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042313959635794166
[2024-04-14 08:30:01,128] INFO: Iter 16200 Summary: 
[2024-04-14 08:30:01,129] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041843510754406454
[2024-04-14 08:30:46,343] INFO: Iter 16300 Summary: 
[2024-04-14 08:30:46,343] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04249579835683107
[2024-04-14 08:31:30,519] INFO: Iter 16400 Summary: 
[2024-04-14 08:31:30,519] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04196301467716694
[2024-04-14 08:32:14,284] INFO: Iter 16500 Summary: 
[2024-04-14 08:32:14,284] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04210621610283852
[2024-04-14 08:32:58,065] INFO: Iter 16600 Summary: 
[2024-04-14 08:32:58,065] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042139885015785694
[2024-04-14 08:33:42,138] INFO: Iter 16700 Summary: 
[2024-04-14 08:33:42,138] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04178464535623789
[2024-04-14 08:34:26,281] INFO: Iter 16800 Summary: 
[2024-04-14 08:34:26,281] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04204643089324236
[2024-04-14 08:35:10,233] INFO: Iter 16900 Summary: 
[2024-04-14 08:35:10,233] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04210298951715231
[2024-04-14 08:35:54,341] INFO: Iter 17000 Summary: 
[2024-04-14 08:35:54,341] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042225491479039194
[2024-04-14 08:36:38,365] INFO: Iter 17100 Summary: 
[2024-04-14 08:36:38,365] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04180577464401722
[2024-04-14 08:37:22,675] INFO: Iter 17200 Summary: 
[2024-04-14 08:37:22,675] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04215360168367624
[2024-04-14 08:38:06,861] INFO: Iter 17300 Summary: 
[2024-04-14 08:38:06,861] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042095840610563755
[2024-04-14 08:38:51,225] INFO: Iter 17400 Summary: 
[2024-04-14 08:38:51,225] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041887905411422253
[2024-04-14 08:39:35,556] INFO: Iter 17500 Summary: 
[2024-04-14 08:39:35,556] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041821642257273195
[2024-04-14 08:40:19,807] INFO: Iter 17600 Summary: 
[2024-04-14 08:40:19,807] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041786889098584655
[2024-04-14 08:41:04,228] INFO: Iter 17700 Summary: 
[2024-04-14 08:41:04,228] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041962621062994004
[2024-04-14 08:41:48,851] INFO: Iter 17800 Summary: 
[2024-04-14 08:41:48,851] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04208275970071554
[2024-04-14 08:42:33,191] INFO: Iter 17900 Summary: 
[2024-04-14 08:42:33,191] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0422338841855526
[2024-04-14 08:43:18,032] INFO: Iter 18000 Summary: 
[2024-04-14 08:43:18,032] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041737793013453484
[2024-04-14 08:44:02,599] INFO: Iter 18100 Summary: 
[2024-04-14 08:44:02,599] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04190987255424261
[2024-04-14 08:44:47,275] INFO: Iter 18200 Summary: 
[2024-04-14 08:44:47,276] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04188865214586258
[2024-04-14 08:45:32,099] INFO: Iter 18300 Summary: 
[2024-04-14 08:45:32,099] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.042087977454066276
[2024-04-14 08:46:16,698] INFO: Iter 18400 Summary: 
[2024-04-14 08:46:16,698] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041915753185749055
[2024-04-14 08:47:01,284] INFO: Iter 18500 Summary: 
[2024-04-14 08:47:01,285] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04160031497478485
[2024-04-14 08:47:46,740] INFO: Iter 18600 Summary: 
[2024-04-14 08:47:46,740] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04169717356562615
[2024-04-14 08:48:32,338] INFO: Iter 18700 Summary: 
[2024-04-14 08:48:32,338] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0418812857568264
[2024-04-14 08:49:16,244] INFO: Iter 18800 Summary: 
[2024-04-14 08:49:16,244] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041642612963914874
[2024-04-14 08:50:02,981] INFO: Iter 18900 Summary: 
[2024-04-14 08:50:02,981] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04156844720244408
[2024-04-14 08:50:46,978] INFO: Iter 19000 Summary: 
[2024-04-14 08:50:46,979] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04183494444936514
[2024-04-14 08:51:28,527] INFO: Iter 19100 Summary: 
[2024-04-14 08:51:28,527] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04185280978679657
[2024-04-14 08:52:10,761] INFO: Iter 19200 Summary: 
[2024-04-14 08:52:10,761] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04168318457901478
[2024-04-14 08:52:51,631] INFO: Iter 19300 Summary: 
[2024-04-14 08:52:51,631] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04130565945059061
[2024-04-14 08:53:37,198] INFO: Iter 19400 Summary: 
[2024-04-14 08:53:37,198] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04164632946252823
[2024-04-14 08:54:22,125] INFO: Iter 19500 Summary: 
[2024-04-14 08:54:22,125] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04152712300419807
[2024-04-14 08:55:03,145] INFO: Iter 19600 Summary: 
[2024-04-14 08:55:03,145] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041748531088232996
[2024-04-14 08:55:43,264] INFO: Iter 19700 Summary: 
[2024-04-14 08:55:43,265] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04166632510721684
[2024-04-14 08:56:24,143] INFO: Iter 19800 Summary: 
[2024-04-14 08:56:24,143] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04131180372089147
[2024-04-14 08:57:06,452] INFO: Iter 19900 Summary: 
[2024-04-14 08:57:06,452] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04167095676064491
[2024-04-14 08:57:49,494] INFO: Iter 20000 Summary: 
[2024-04-14 08:57:49,494] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04146988652646542
[2024-04-14 08:58:33,242] INFO: Iter 20100 Summary: 
[2024-04-14 08:58:33,242] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04135740488767624
[2024-04-14 08:59:15,933] INFO: Iter 20200 Summary: 
[2024-04-14 08:59:15,933] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04136976085603237
[2024-04-14 08:59:58,065] INFO: Iter 20300 Summary: 
[2024-04-14 08:59:58,065] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041460293158888814
[2024-04-14 09:00:40,445] INFO: Iter 20400 Summary: 
[2024-04-14 09:00:40,445] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04126606736332178
[2024-04-14 09:01:30,111] INFO: Iter 20500 Summary: 
[2024-04-14 09:01:30,111] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04181351907551289
[2024-04-14 09:02:12,970] INFO: Iter 20600 Summary: 
[2024-04-14 09:02:12,970] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041403631456196306
[2024-04-14 09:02:56,492] INFO: Iter 20700 Summary: 
[2024-04-14 09:02:56,492] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041323246099054814
[2024-04-14 09:03:37,733] INFO: Iter 20800 Summary: 
[2024-04-14 09:03:37,733] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04146322265267372
[2024-04-14 09:04:20,614] INFO: Iter 20900 Summary: 
[2024-04-14 09:04:20,614] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041212883032858375
[2024-04-14 09:05:01,533] INFO: Iter 21000 Summary: 
[2024-04-14 09:05:01,533] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04139200091362
[2024-04-14 09:05:41,814] INFO: Iter 21100 Summary: 
[2024-04-14 09:05:41,814] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04129634510725737
[2024-04-14 09:06:21,319] INFO: Iter 21200 Summary: 
[2024-04-14 09:06:21,320] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04112716563045979
[2024-04-14 09:07:04,300] INFO: Iter 21300 Summary: 
[2024-04-14 09:07:04,300] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04145818792283535
[2024-04-14 09:07:48,384] INFO: Iter 21400 Summary: 
[2024-04-14 09:07:48,384] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041198228932917115
[2024-04-14 09:08:33,567] INFO: Iter 21500 Summary: 
[2024-04-14 09:08:33,567] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041328260339796544
[2024-04-14 09:09:18,284] INFO: Iter 21600 Summary: 
[2024-04-14 09:09:18,284] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04102244924753904
[2024-04-14 09:10:04,097] INFO: Iter 21700 Summary: 
[2024-04-14 09:10:04,097] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04141542706638575
[2024-04-14 09:10:48,404] INFO: Iter 21800 Summary: 
[2024-04-14 09:10:48,404] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041561809070408344
[2024-04-14 09:11:33,492] INFO: Iter 21900 Summary: 
[2024-04-14 09:11:33,493] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04128662697970867
[2024-04-14 09:12:18,618] INFO: Iter 22000 Summary: 
[2024-04-14 09:12:18,618] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041462562903761865
[2024-04-14 09:13:01,798] INFO: Iter 22100 Summary: 
[2024-04-14 09:13:01,798] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0412932051345706
[2024-04-14 09:13:39,900] INFO: Iter 22200 Summary: 
[2024-04-14 09:13:39,900] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04084192480891943
[2024-04-14 09:14:17,233] INFO: Iter 22300 Summary: 
[2024-04-14 09:14:17,234] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041025930866599086
[2024-04-14 09:14:54,482] INFO: Iter 22400 Summary: 
[2024-04-14 09:14:54,482] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04104127593338489
[2024-04-14 09:15:31,933] INFO: Iter 22500 Summary: 
[2024-04-14 09:15:31,933] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04083325915038585
[2024-04-14 09:16:09,399] INFO: Iter 22600 Summary: 
[2024-04-14 09:16:09,399] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04120816469192505
[2024-04-14 09:16:47,122] INFO: Iter 22700 Summary: 
[2024-04-14 09:16:47,122] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04119227882474661
[2024-04-14 09:17:24,732] INFO: Iter 22800 Summary: 
[2024-04-14 09:17:24,732] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04131187159568071
[2024-04-14 09:18:02,386] INFO: Iter 22900 Summary: 
[2024-04-14 09:18:02,386] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040817387104034424
[2024-04-14 09:18:40,108] INFO: Iter 23000 Summary: 
[2024-04-14 09:18:40,108] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040992100052535535
[2024-04-14 09:19:17,841] INFO: Iter 23100 Summary: 
[2024-04-14 09:19:17,841] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04121426943689585
[2024-04-14 09:19:55,501] INFO: Iter 23200 Summary: 
[2024-04-14 09:19:55,501] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04103895898908377
[2024-04-14 09:20:33,099] INFO: Iter 23300 Summary: 
[2024-04-14 09:20:33,099] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041022661253809926
[2024-04-14 09:21:10,877] INFO: Iter 23400 Summary: 
[2024-04-14 09:21:10,878] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04074965540319681
[2024-04-14 09:21:48,349] INFO: Iter 23500 Summary: 
[2024-04-14 09:21:48,349] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04121650710701943
[2024-04-14 09:22:25,963] INFO: Iter 23600 Summary: 
[2024-04-14 09:22:25,964] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04086611565202475
[2024-04-14 09:23:03,678] INFO: Iter 23700 Summary: 
[2024-04-14 09:23:03,678] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04099171046167612
[2024-04-14 09:23:41,343] INFO: Iter 23800 Summary: 
[2024-04-14 09:23:41,343] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04089241862297058
[2024-04-14 09:24:18,989] INFO: Iter 23900 Summary: 
[2024-04-14 09:24:18,989] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04129452295601368
[2024-04-14 09:24:56,846] INFO: Iter 24000 Summary: 
[2024-04-14 09:24:56,846] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040669051744043824
[2024-04-14 09:25:34,764] INFO: Iter 24100 Summary: 
[2024-04-14 09:25:34,764] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04114795848727226
[2024-04-14 09:26:12,726] INFO: Iter 24200 Summary: 
[2024-04-14 09:26:12,726] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.041075863912701606
[2024-04-14 09:26:50,620] INFO: Iter 24300 Summary: 
[2024-04-14 09:26:50,620] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040974846296012404
[2024-04-14 09:27:28,603] INFO: Iter 24400 Summary: 
[2024-04-14 09:27:28,603] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040544551238417624
[2024-04-14 09:28:06,611] INFO: Iter 24500 Summary: 
[2024-04-14 09:28:06,611] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040841355361044406
[2024-04-14 09:28:44,626] INFO: Iter 24600 Summary: 
[2024-04-14 09:28:44,626] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04100078772753477
[2024-04-14 09:29:22,868] INFO: Iter 24700 Summary: 
[2024-04-14 09:29:22,868] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04087874535471201
[2024-04-14 09:30:02,289] INFO: Iter 24800 Summary: 
[2024-04-14 09:30:02,289] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04073653295636177
[2024-04-14 09:30:47,270] INFO: Iter 24900 Summary: 
[2024-04-14 09:30:47,270] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04079355258494616
[2024-04-14 09:31:26,553] INFO: Iter 25000 Summary: 
[2024-04-14 09:31:26,553] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040489259734749795
[2024-04-14 09:32:04,612] INFO: Iter 25100 Summary: 
[2024-04-14 09:32:04,612] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04073860514909029
[2024-04-14 09:32:42,676] INFO: Iter 25200 Summary: 
[2024-04-14 09:32:42,677] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04101153381168842
[2024-04-14 09:33:20,573] INFO: Iter 25300 Summary: 
[2024-04-14 09:33:20,573] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04084648266434669
[2024-04-14 09:33:58,656] INFO: Iter 25400 Summary: 
[2024-04-14 09:33:58,656] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04093158815056085
[2024-04-14 09:34:36,784] INFO: Iter 25500 Summary: 
[2024-04-14 09:34:36,784] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040813458301126954
[2024-04-14 09:35:15,051] INFO: Iter 25600 Summary: 
[2024-04-14 09:35:15,051] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04101076625287533
[2024-04-14 09:35:53,399] INFO: Iter 25700 Summary: 
[2024-04-14 09:35:53,399] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04044463008642197
[2024-04-14 09:36:31,572] INFO: Iter 25800 Summary: 
[2024-04-14 09:36:31,573] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04093694262206554
[2024-04-14 09:37:10,147] INFO: Iter 25900 Summary: 
[2024-04-14 09:37:10,147] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04048439480364323
[2024-04-14 09:37:48,376] INFO: Iter 26000 Summary: 
[2024-04-14 09:37:48,376] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040893813446164134
[2024-04-14 09:38:26,223] INFO: Iter 26100 Summary: 
[2024-04-14 09:38:26,223] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040928549505770205
[2024-04-14 09:39:04,096] INFO: Iter 26200 Summary: 
[2024-04-14 09:39:04,096] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04074584282934666
[2024-04-14 09:39:42,339] INFO: Iter 26300 Summary: 
[2024-04-14 09:39:42,339] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04049063686281443
[2024-04-14 09:40:20,763] INFO: Iter 26400 Summary: 
[2024-04-14 09:40:20,763] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04073354005813599
[2024-04-14 09:40:59,547] INFO: Iter 26500 Summary: 
[2024-04-14 09:40:59,547] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04098173201084137
[2024-04-14 09:41:38,584] INFO: Iter 26600 Summary: 
[2024-04-14 09:41:38,584] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04060424692928791
[2024-04-14 09:42:17,703] INFO: Iter 26700 Summary: 
[2024-04-14 09:42:17,703] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04090130154043436
[2024-04-14 09:42:56,798] INFO: Iter 26800 Summary: 
[2024-04-14 09:42:56,798] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04036217715591192
[2024-04-14 09:43:36,121] INFO: Iter 26900 Summary: 
[2024-04-14 09:43:36,121] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040670895613729954
[2024-04-14 09:44:16,635] INFO: Iter 27000 Summary: 
[2024-04-14 09:44:16,635] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040790806263685225
[2024-04-14 09:44:55,731] INFO: Iter 27100 Summary: 
[2024-04-14 09:44:55,731] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04070867169648409
[2024-04-14 09:45:35,019] INFO: Iter 27200 Summary: 
[2024-04-14 09:45:35,019] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0406715876609087
[2024-04-14 09:46:14,298] INFO: Iter 27300 Summary: 
[2024-04-14 09:46:14,298] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04072288099676371
[2024-04-14 09:46:53,669] INFO: Iter 27400 Summary: 
[2024-04-14 09:46:53,670] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04075149271637201
[2024-04-14 09:47:33,245] INFO: Iter 27500 Summary: 
[2024-04-14 09:47:33,245] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040671811029315
[2024-04-14 09:48:13,011] INFO: Iter 27600 Summary: 
[2024-04-14 09:48:13,011] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040530340410768986
[2024-04-14 09:48:52,859] INFO: Iter 27700 Summary: 
[2024-04-14 09:48:52,859] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04060431756079197
[2024-04-14 09:49:32,652] INFO: Iter 27800 Summary: 
[2024-04-14 09:49:32,652] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040632077530026435
[2024-04-14 09:50:12,450] INFO: Iter 27900 Summary: 
[2024-04-14 09:50:12,450] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04047549542039633
[2024-04-14 09:50:52,384] INFO: Iter 28000 Summary: 
[2024-04-14 09:50:52,384] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040772031620144845
[2024-04-14 09:51:32,541] INFO: Iter 28100 Summary: 
[2024-04-14 09:51:32,541] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040835654363036156
[2024-04-14 09:52:12,420] INFO: Iter 28200 Summary: 
[2024-04-14 09:52:12,420] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04080105155706406
[2024-04-14 09:52:52,583] INFO: Iter 28300 Summary: 
[2024-04-14 09:52:52,583] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04057328462600708
[2024-04-14 09:53:32,668] INFO: Iter 28400 Summary: 
[2024-04-14 09:53:32,668] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04059316895902157
[2024-04-14 09:54:12,827] INFO: Iter 28500 Summary: 
[2024-04-14 09:54:12,827] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0406107696518302
[2024-04-14 09:54:53,165] INFO: Iter 28600 Summary: 
[2024-04-14 09:54:53,165] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04082181241363287
[2024-04-14 09:55:33,588] INFO: Iter 28700 Summary: 
[2024-04-14 09:55:33,588] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040593806765973565
[2024-04-14 09:56:13,882] INFO: Iter 28800 Summary: 
[2024-04-14 09:56:13,882] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04054517786949873
[2024-04-14 09:56:54,205] INFO: Iter 28900 Summary: 
[2024-04-14 09:56:54,205] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040378008857369425
[2024-04-14 09:57:37,680] INFO: Iter 29000 Summary: 
[2024-04-14 09:57:37,680] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04063072867691517
[2024-04-14 09:58:23,656] INFO: Iter 29100 Summary: 
[2024-04-14 09:58:23,656] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04078093651682138
[2024-04-14 09:59:10,140] INFO: Iter 29200 Summary: 
[2024-04-14 09:59:10,140] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0403603882715106
[2024-04-14 09:59:56,510] INFO: Iter 29300 Summary: 
[2024-04-14 09:59:56,510] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04035043735057116
[2024-04-14 10:00:42,963] INFO: Iter 29400 Summary: 
[2024-04-14 10:00:42,963] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04029585633426905
[2024-04-14 10:01:29,413] INFO: Iter 29500 Summary: 
[2024-04-14 10:01:29,414] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.040510753467679024
[2024-04-14 10:02:15,970] INFO: Iter 29600 Summary: 
[2024-04-14 10:02:15,970] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04037189520895481
[2024-04-14 10:03:02,934] INFO: Iter 29700 Summary: 
[2024-04-14 10:03:02,934] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04021015789359808
[2024-04-14 10:03:49,287] INFO: Iter 29800 Summary: 
[2024-04-14 10:03:49,287] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04043097678571939
[2024-04-14 10:04:36,037] INFO: Iter 29900 Summary: 
[2024-04-14 10:04:36,037] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.0406945176422596
[2024-04-14 10:05:22,531] INFO: Iter 30000 Summary: 
[2024-04-14 10:05:22,531] INFO: 	 lr: 0.00030000000000000073 	 Training loss: 0.04027547392994166
[2024-04-14 10:06:09,396] INFO: Iter 30100 Summary: 
[2024-04-14 10:06:09,396] INFO: 	 lr: 1.2900000000000026e-05 	 Training loss: 0.03963688496500253
[2024-04-14 10:06:57,685] INFO: Iter 30200 Summary: 
[2024-04-14 10:06:57,685] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.039205986484885214
[2024-04-14 10:07:44,546] INFO: Iter 30300 Summary: 
[2024-04-14 10:07:44,546] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038974746502935885
[2024-04-14 10:08:31,044] INFO: Iter 30400 Summary: 
[2024-04-14 10:08:31,044] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.0389280142635107
[2024-04-14 10:09:17,884] INFO: Iter 30500 Summary: 
[2024-04-14 10:09:17,884] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03875407632440329
[2024-04-14 10:10:05,121] INFO: Iter 30600 Summary: 
[2024-04-14 10:10:05,121] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03876544043421745
[2024-04-14 10:10:52,199] INFO: Iter 30700 Summary: 
[2024-04-14 10:10:52,199] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038737273029983046
[2024-04-14 10:11:39,187] INFO: Iter 30800 Summary: 
[2024-04-14 10:11:39,187] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03905615009367466
[2024-04-14 10:12:26,222] INFO: Iter 30900 Summary: 
[2024-04-14 10:12:26,222] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038699739687144755
[2024-04-14 10:13:13,248] INFO: Iter 31000 Summary: 
[2024-04-14 10:13:13,248] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03906995929777622
[2024-04-14 10:14:00,393] INFO: Iter 31100 Summary: 
[2024-04-14 10:14:00,393] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038898994885385035
[2024-04-14 10:14:47,760] INFO: Iter 31200 Summary: 
[2024-04-14 10:14:47,760] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03894417583942413
[2024-04-14 10:15:35,224] INFO: Iter 31300 Summary: 
[2024-04-14 10:15:35,224] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038430392183363436
[2024-04-14 10:16:22,365] INFO: Iter 31400 Summary: 
[2024-04-14 10:16:22,365] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03870140220969916
[2024-04-14 10:17:09,943] INFO: Iter 31500 Summary: 
[2024-04-14 10:17:09,943] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03857300002127886
[2024-04-14 10:17:57,368] INFO: Iter 31600 Summary: 
[2024-04-14 10:17:57,368] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038780533559620384
[2024-04-14 10:18:45,217] INFO: Iter 31700 Summary: 
[2024-04-14 10:18:45,217] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.0386928228661418
[2024-04-14 10:19:33,048] INFO: Iter 31800 Summary: 
[2024-04-14 10:19:33,048] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03870753478258848
[2024-04-14 10:20:20,452] INFO: Iter 31900 Summary: 
[2024-04-14 10:20:20,452] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03856179535388946
[2024-04-14 10:21:07,826] INFO: Iter 32000 Summary: 
[2024-04-14 10:21:07,826] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03871326204389334
[2024-04-14 10:21:56,379] INFO: Iter 32100 Summary: 
[2024-04-14 10:21:56,379] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03875498954206705
[2024-04-14 10:22:44,602] INFO: Iter 32200 Summary: 
[2024-04-14 10:22:44,602] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03853599186986685
[2024-04-14 10:23:32,466] INFO: Iter 32300 Summary: 
[2024-04-14 10:23:32,466] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03855457369238138
[2024-04-14 10:24:20,422] INFO: Iter 32400 Summary: 
[2024-04-14 10:24:20,422] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038536208234727386
[2024-04-14 10:25:08,139] INFO: Iter 32500 Summary: 
[2024-04-14 10:25:08,140] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03868399612605572
[2024-04-14 10:25:55,987] INFO: Iter 32600 Summary: 
[2024-04-14 10:25:55,987] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03856461193412542
[2024-04-14 10:26:43,842] INFO: Iter 32700 Summary: 
[2024-04-14 10:26:43,843] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03838774137198925
[2024-04-14 10:27:31,605] INFO: Iter 32800 Summary: 
[2024-04-14 10:27:31,605] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03848966345191002
[2024-04-14 10:28:20,013] INFO: Iter 32900 Summary: 
[2024-04-14 10:28:20,013] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03858163397759199
[2024-04-14 10:29:08,056] INFO: Iter 33000 Summary: 
[2024-04-14 10:29:08,056] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038680192939937116
[2024-04-14 10:29:56,505] INFO: Iter 33100 Summary: 
[2024-04-14 10:29:56,505] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03835547246038914
[2024-04-14 10:30:44,877] INFO: Iter 33200 Summary: 
[2024-04-14 10:30:44,877] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03850351247936487
[2024-04-14 10:31:37,505] INFO: Iter 33300 Summary: 
[2024-04-14 10:31:37,505] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03841136686503887
[2024-04-14 10:32:22,307] INFO: Iter 33400 Summary: 
[2024-04-14 10:32:22,307] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03855093352496624
[2024-04-14 10:33:02,698] INFO: Iter 33500 Summary: 
[2024-04-14 10:33:02,698] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03818375211209059
[2024-04-14 10:33:42,528] INFO: Iter 33600 Summary: 
[2024-04-14 10:33:42,528] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038529498353600505
[2024-04-14 10:34:21,777] INFO: Iter 33700 Summary: 
[2024-04-14 10:34:21,777] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038391669429838654
[2024-04-14 10:35:01,480] INFO: Iter 33800 Summary: 
[2024-04-14 10:35:01,480] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03848978538066149
[2024-04-14 10:35:41,260] INFO: Iter 33900 Summary: 
[2024-04-14 10:35:41,260] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03854604449123144
[2024-04-14 10:36:20,974] INFO: Iter 34000 Summary: 
[2024-04-14 10:36:20,974] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038504437133669855
[2024-04-14 10:37:00,714] INFO: Iter 34100 Summary: 
[2024-04-14 10:37:00,714] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03840904731303454
[2024-04-14 10:37:40,645] INFO: Iter 34200 Summary: 
[2024-04-14 10:37:40,645] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038661586046218874
[2024-04-14 10:38:20,776] INFO: Iter 34300 Summary: 
[2024-04-14 10:38:20,776] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038291349671781064
[2024-04-14 10:39:01,058] INFO: Iter 34400 Summary: 
[2024-04-14 10:39:01,058] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038332269005477426
[2024-04-14 10:39:41,178] INFO: Iter 34500 Summary: 
[2024-04-14 10:39:41,178] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038342388495802876
[2024-04-14 10:40:21,168] INFO: Iter 34600 Summary: 
[2024-04-14 10:40:21,168] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03828848470002413
[2024-04-14 10:41:00,998] INFO: Iter 34700 Summary: 
[2024-04-14 10:41:00,998] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038109243251383304
[2024-04-14 10:41:42,862] INFO: Iter 34800 Summary: 
[2024-04-14 10:41:42,862] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03843347769230604
[2024-04-14 10:42:22,665] INFO: Iter 34900 Summary: 
[2024-04-14 10:42:22,665] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03833787016570568
[2024-04-14 10:43:02,441] INFO: Iter 35000 Summary: 
[2024-04-14 10:43:02,441] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03828348055481911
[2024-04-14 10:43:42,108] INFO: Iter 35100 Summary: 
[2024-04-14 10:43:42,108] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03828899048268795
[2024-04-14 10:44:21,786] INFO: Iter 35200 Summary: 
[2024-04-14 10:44:21,786] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038341741003096105
[2024-04-14 10:45:01,447] INFO: Iter 35300 Summary: 
[2024-04-14 10:45:01,447] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038531740680336955
[2024-04-14 10:45:40,950] INFO: Iter 35400 Summary: 
[2024-04-14 10:45:40,950] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03816593244671822
[2024-04-14 10:46:20,692] INFO: Iter 35500 Summary: 
[2024-04-14 10:46:20,692] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03826426040381193
[2024-04-14 10:47:00,384] INFO: Iter 35600 Summary: 
[2024-04-14 10:47:00,384] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038408880457282066
[2024-04-14 10:47:40,139] INFO: Iter 35700 Summary: 
[2024-04-14 10:47:40,139] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03841283060610294
[2024-04-14 10:48:19,756] INFO: Iter 35800 Summary: 
[2024-04-14 10:48:19,756] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038460003361105916
[2024-04-14 10:48:59,593] INFO: Iter 35900 Summary: 
[2024-04-14 10:48:59,593] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03811323922127485
[2024-04-14 10:49:39,365] INFO: Iter 36000 Summary: 
[2024-04-14 10:49:39,365] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038452697955071925
[2024-04-14 10:50:19,010] INFO: Iter 36100 Summary: 
[2024-04-14 10:50:19,010] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03827371396124363
[2024-04-14 10:50:58,877] INFO: Iter 36200 Summary: 
[2024-04-14 10:50:58,878] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03805226996541023
[2024-04-14 10:51:38,595] INFO: Iter 36300 Summary: 
[2024-04-14 10:51:38,595] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03847948521375656
[2024-04-14 10:52:18,590] INFO: Iter 36400 Summary: 
[2024-04-14 10:52:18,590] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03832920867949724
[2024-04-14 10:52:58,632] INFO: Iter 36500 Summary: 
[2024-04-14 10:52:58,633] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03822679560631514
[2024-04-14 10:53:38,386] INFO: Iter 36600 Summary: 
[2024-04-14 10:53:38,386] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03843443289399147
[2024-04-14 10:54:18,200] INFO: Iter 36700 Summary: 
[2024-04-14 10:54:18,200] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03793084636330604
[2024-04-14 10:54:57,971] INFO: Iter 36800 Summary: 
[2024-04-14 10:54:57,971] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03827891431748867
[2024-04-14 10:55:37,415] INFO: Iter 36900 Summary: 
[2024-04-14 10:55:37,415] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.0383205596357584
[2024-04-14 10:56:16,723] INFO: Iter 37000 Summary: 
[2024-04-14 10:56:16,723] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03829924285411835
[2024-04-14 10:56:56,298] INFO: Iter 37100 Summary: 
[2024-04-14 10:56:56,298] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038260043263435364
[2024-04-14 10:57:42,222] INFO: Iter 37200 Summary: 
[2024-04-14 10:57:42,222] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03806410167366266
[2024-04-14 10:58:23,477] INFO: Iter 37300 Summary: 
[2024-04-14 10:58:23,477] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03826087836176157
[2024-04-14 10:59:03,333] INFO: Iter 37400 Summary: 
[2024-04-14 10:59:03,333] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038063391149044036
[2024-04-14 10:59:42,862] INFO: Iter 37500 Summary: 
[2024-04-14 10:59:42,863] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03835949372500181
[2024-04-14 11:00:22,590] INFO: Iter 37600 Summary: 
[2024-04-14 11:00:22,591] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03835254441946745
[2024-04-14 11:01:02,347] INFO: Iter 37700 Summary: 
[2024-04-14 11:01:02,347] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038190013766288756
[2024-04-14 11:01:42,116] INFO: Iter 37800 Summary: 
[2024-04-14 11:01:42,116] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03831912454217672
[2024-04-14 11:02:21,657] INFO: Iter 37900 Summary: 
[2024-04-14 11:02:21,657] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038293688856065274
[2024-04-14 11:03:01,458] INFO: Iter 38000 Summary: 
[2024-04-14 11:03:01,458] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03839669346809387
[2024-04-14 11:03:41,289] INFO: Iter 38100 Summary: 
[2024-04-14 11:03:41,289] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03835597302764654
[2024-04-14 11:04:21,173] INFO: Iter 38200 Summary: 
[2024-04-14 11:04:21,173] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03819720722734928
[2024-04-14 11:05:00,918] INFO: Iter 38300 Summary: 
[2024-04-14 11:05:00,919] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03830830715596676
[2024-04-14 11:05:41,055] INFO: Iter 38400 Summary: 
[2024-04-14 11:05:41,055] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038231386616826055
[2024-04-14 11:06:25,931] INFO: Iter 38500 Summary: 
[2024-04-14 11:06:25,931] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03810511752963066
[2024-04-14 11:07:10,526] INFO: Iter 38600 Summary: 
[2024-04-14 11:07:10,526] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03830671291798353
[2024-04-14 11:07:53,892] INFO: Iter 38700 Summary: 
[2024-04-14 11:07:53,892] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03811914563179016
[2024-04-14 11:08:36,712] INFO: Iter 38800 Summary: 
[2024-04-14 11:08:36,712] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038189033046364784
[2024-04-14 11:09:18,927] INFO: Iter 38900 Summary: 
[2024-04-14 11:09:18,927] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.0382316979765892
[2024-04-14 11:10:00,452] INFO: Iter 39000 Summary: 
[2024-04-14 11:10:00,452] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03838649462908506
[2024-04-14 11:10:40,377] INFO: Iter 39100 Summary: 
[2024-04-14 11:10:40,377] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.037962994687259194
[2024-04-14 11:11:19,942] INFO: Iter 39200 Summary: 
[2024-04-14 11:11:19,942] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038157340250909326
[2024-04-14 11:11:59,400] INFO: Iter 39300 Summary: 
[2024-04-14 11:11:59,401] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03856023039668798
[2024-04-14 11:12:38,869] INFO: Iter 39400 Summary: 
[2024-04-14 11:12:38,869] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03825735721737147
[2024-04-14 11:13:18,642] INFO: Iter 39500 Summary: 
[2024-04-14 11:13:18,642] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03818476937711239
[2024-04-14 11:13:59,882] INFO: Iter 39600 Summary: 
[2024-04-14 11:13:59,882] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.038167846985161305
[2024-04-14 11:14:41,883] INFO: Iter 39700 Summary: 
[2024-04-14 11:14:41,883] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03796481650322676
[2024-04-14 11:15:25,041] INFO: Iter 39800 Summary: 
[2024-04-14 11:15:25,041] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03824270717799663
[2024-04-14 11:16:08,022] INFO: Iter 39900 Summary: 
[2024-04-14 11:16:08,022] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03791617993265391
[2024-04-14 11:16:51,857] INFO: Iter 40000 Summary: 
[2024-04-14 11:16:51,857] INFO: 	 lr: 1.000000000000002e-05 	 Training loss: 0.03830735817551613
